## ğŸ¥ Demo
| Input                | Output                | Input                | Output                |
|----------------------|-----------------------|----------------------|-----------------------|
|<img src="examples/image/anime1.png" width="360">|<video src="https://github.com/user-attachments/assets/636c3ff5-210e-44b8-b901-acf828071133" width="360"> </video>|<img src="examples/image/female_diaosu.png" width="360">|<video src="https://github.com/user-attachments/assets/e8207300-2569-47d1-9ad4-4b4c9b0f0bd4" width="360"> </video>|
|<img src="examples/image/hair.png" width="360">|<video src="https://github.com/user-attachments/assets/dcb755c1-de01-4afe-8b4f-0e0b2c2439c1" width="360"> </video>|<img src="examples/image/leonnado.jpg" width="360">|<video src="https://github.com/user-attachments/assets/b50e61bb-62d4-469d-b402-b37cda3fbd27" width="360"> </video>|


For more visual demos, please visit our [**Page**](https://jixiaozhong.github.io/Sonic/).

## ğŸ§© Community Contributions
If you develop/use Sonic in your projects, welcome to let us know.

- ComfyUI version of Sonic: [**ComfyUI_Sonic**](https://github.com/smthemex/ComfyUI_Sonic)


## ğŸ“œ Requirements
* An NVIDIA GPU with CUDA support is required. 
  * The model is tested on a single 32G GPU.
* Tested operating system: Linux

## ğŸ”‘ Inference

### Installtion

- install pytorch
```shell
  pip install -r requirements.txt
```
- All models are stored in `checkpoints` by default, and the file structure is as follows
```shell
Sonic
  â”œâ”€â”€checkpoints
  â”‚  â”œâ”€â”€Sonic
  â”‚  â”‚  â”œâ”€â”€audio2bucket.pth
  â”‚  â”‚  â”œâ”€â”€audio2token.pth
  â”‚  â”‚  â”œâ”€â”€unet.pth
  â”‚  â”œâ”€â”€stable-video-diffusion-img2vid-xt
  â”‚  â”‚  â”œâ”€â”€...
  â”‚  â”œâ”€â”€whisper-tiny
  â”‚  â”‚  â”œâ”€â”€...
  â”‚  â”œâ”€â”€RIFE
  â”‚  â”‚  â”œâ”€â”€flownet.pkl
  â”‚  â”œâ”€â”€yoloface_v5m.pt
  â”œâ”€â”€...
```
Download by `huggingface-cli` follow
```shell
  python3 -m pip install "huggingface_hub[cli]"
  huggingface-cli download LeonJoe13/Sonic --local-dir  checkpoints
  huggingface-cli download stabilityai/stable-video-diffusion-img2vid-xt --local-dir  checkpoints/stable-video-diffusion-img2vid-xt
  huggingface-cli download openai/whisper-tiny --local-dir checkpoints/whisper-tiny
```

or manully download [pretrain model](https://drive.google.com/drive/folders/1oe8VTPUy0-MHHW2a_NJ1F8xL-0VN5G7W?usp=drive_link), [svd-xt](https://huggingface.co/stabilityai/stable-video-diffusion-img2vid-xt) and [whisper-tiny](https://huggingface.co/openai/whisper-tiny) to checkpoints/ 

## ğŸ¬ Inference API

### Celeryé…ç½®
```
celery_app.py
```

### å¯åŠ¨Celery workerï¼š
```
celery -A tasks worker --loglevel=info
```

### å¯åŠ¨FastAPIæœåŠ¡ï¼š
```
uvicorn main:app --host 0.0.0.0 --port 8000
```

### åˆ›å»ºè§†é¢‘ç”Ÿæˆä»»åŠ¡ï¼š
```
curl -X POST "http://localhost:8000/generate_video" \
-H "Content-Type: application/json" \
-d '{"image_url":"https://example.com/image.jpg","audio_url":"https://example.com/audio.wav","dynamic_scale":1.0}'
```
### æŸ¥çœ‹è§†é¢‘ç”Ÿæˆç»“æœï¼š
```
curl "http://localhost:8000/task/{task_id}"
```


### Supervisordé…ç½®
```
[program:sonic_api]
command=bash -c "cd /data/Sonic && /home/work/data/miniconda3/envs/Sonic/bin/uvicorn main:app --host 0.0.0.0 --port 8005 --reload"
autostart=true
autorestart=true
stderr_logfile=/var/log/supervisor/sonic_api.err.log
stdout_logfile=/var/log/supervisor/sonic_api.out.log

[program:sonic_celery]
command=bash -c "cd /data/Sonic && /home/work/data/miniconda3/envs/Sonic/bin/celery -A tasks worker --loglevel=info --pool=threads"
autostart=true
autorestart=true
stderr_logfile=/var/log/supervisor/sonic_celery.err.log
stdout_logfile=/var/log/supervisor/sonic_celery.out.log
```